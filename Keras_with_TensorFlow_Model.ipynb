{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34d1dec9-d260-4b65-9bb1-5383e3c9b99f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:51:51.803328Z",
     "iopub.status.busy": "2022-04-01T04:51:51.802770Z",
     "iopub.status.idle": "2022-04-01T04:51:51.809424Z",
     "shell.execute_reply": "2022-04-01T04:51:51.808718Z",
     "shell.execute_reply.started": "2022-04-01T04:51:51.803299Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a07b770-0d94-4f09-90eb-67e9fd3b91c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:51:51.811016Z",
     "iopub.status.busy": "2022-04-01T04:51:51.810654Z",
     "iopub.status.idle": "2022-04-01T04:51:51.815204Z",
     "shell.execute_reply": "2022-04-01T04:51:51.814548Z",
     "shell.execute_reply.started": "2022-04-01T04:51:51.810994Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, auc\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af7bdabe-8e63-43df-9515-32f6fca4219d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:51:51.816078Z",
     "iopub.status.busy": "2022-04-01T04:51:51.815934Z",
     "iopub.status.idle": "2022-04-01T04:51:51.819014Z",
     "shell.execute_reply": "2022-04-01T04:51:51.818441Z",
     "shell.execute_reply.started": "2022-04-01T04:51:51.816061Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip uninstall scikit-learn -y\n",
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59d961c1-6447-4d93-9702-bd56b089e377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:51:51.819864Z",
     "iopub.status.busy": "2022-04-01T04:51:51.819721Z",
     "iopub.status.idle": "2022-04-01T04:51:54.206380Z",
     "shell.execute_reply": "2022-04-01T04:51:54.205768Z",
     "shell.execute_reply.started": "2022-04-01T04:51:51.819847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.19.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95351a5d-5e8e-4d76-85fc-b0e30330eaad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:51:54.208332Z",
     "iopub.status.busy": "2022-04-01T04:51:54.208149Z",
     "iopub.status.idle": "2022-04-01T04:51:54.212397Z",
     "shell.execute_reply": "2022-04-01T04:51:54.211780Z",
     "shell.execute_reply.started": "2022-04-01T04:51:54.208310Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c202c0-0fca-4d9b-82da-bd9c5f6bba19",
   "metadata": {},
   "source": [
    "## Load & Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae15b86d-0ab0-4c91-9e29-df5ac76a23e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:51:54.213187Z",
     "iopub.status.busy": "2022-04-01T04:51:54.213040Z",
     "iopub.status.idle": "2022-04-01T04:52:00.078729Z",
     "shell.execute_reply": "2022-04-01T04:52:00.077895Z",
     "shell.execute_reply.started": "2022-04-01T04:51:54.213170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txns = pd.read_csv('./train.csv')\n",
    "txns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "535610e8-fed7-4bdd-be2d-2ec290f1fc99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:52:00.079859Z",
     "iopub.status.busy": "2022-04-01T04:52:00.079681Z",
     "iopub.status.idle": "2022-04-01T04:52:00.653760Z",
     "shell.execute_reply": "2022-04-01T04:52:00.653278Z",
     "shell.execute_reply.started": "2022-04-01T04:52:00.079838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6', 'var_7', 'var_8', 'var_9', 'var_10', 'var_11', 'var_12', 'var_13', 'var_14', 'var_15', 'var_16', 'var_17', 'var_18', 'var_19', 'var_20', 'var_21', 'var_22', 'var_23', 'var_24', 'var_25', 'var_26', 'var_27', 'var_28', 'var_29', 'var_30', 'var_31', 'var_32', 'var_33', 'var_34', 'var_35', 'var_36', 'var_37', 'var_38', 'var_39', 'var_40', 'var_41', 'var_42', 'var_43', 'var_44', 'var_45', 'var_46', 'var_47', 'var_48', 'var_49', 'var_50', 'var_51', 'var_52', 'var_53', 'var_54', 'var_55', 'var_56', 'var_57', 'var_58', 'var_59', 'var_60', 'var_61', 'var_62', 'var_63', 'var_64', 'var_65', 'var_66', 'var_67', 'var_68', 'var_69', 'var_70', 'var_71', 'var_72', 'var_73', 'var_74', 'var_75', 'var_76', 'var_77', 'var_78', 'var_79', 'var_80', 'var_81', 'var_82', 'var_83', 'var_84', 'var_85', 'var_86', 'var_87', 'var_88', 'var_89', 'var_90', 'var_91', 'var_92', 'var_93', 'var_94', 'var_95', 'var_96', 'var_97', 'var_98', 'var_99', 'var_100', 'var_101', 'var_102', 'var_103', 'var_104', 'var_105', 'var_106', 'var_107', 'var_108', 'var_109', 'var_110', 'var_111', 'var_112', 'var_113', 'var_114', 'var_115', 'var_116', 'var_117', 'var_118', 'var_119', 'var_120', 'var_121', 'var_122', 'var_123', 'var_124', 'var_125', 'var_126', 'var_127', 'var_128', 'var_129', 'var_130', 'var_131', 'var_132', 'var_133', 'var_134', 'var_135', 'var_136', 'var_137', 'var_138', 'var_139', 'var_140', 'var_141', 'var_142', 'var_143', 'var_144', 'var_145', 'var_146', 'var_147', 'var_148', 'var_149', 'var_150', 'var_151', 'var_152', 'var_153', 'var_154', 'var_155', 'var_156', 'var_157', 'var_158', 'var_159', 'var_160', 'var_161', 'var_162', 'var_163', 'var_164', 'var_165', 'var_166', 'var_167', 'var_168', 'var_169', 'var_170', 'var_171', 'var_172', 'var_173', 'var_174', 'var_175', 'var_176', 'var_177', 'var_178', 'var_179', 'var_180', 'var_181', 'var_182', 'var_183', 'var_184', 'var_185', 'var_186', 'var_187', 'var_188', 'var_189', 'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195', 'var_196', 'var_197', 'var_198', 'var_199']\n"
     ]
    }
   ],
   "source": [
    "properties = list(txns.columns.values)\n",
    "properties.remove('ID_code')\n",
    "properties.remove('target')\n",
    "print(properties)\n",
    "X = txns[properties]\n",
    "y = txns['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "718e49d6-d1b2-463d-8121-110c2fb07558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:52:00.655361Z",
     "iopub.status.busy": "2022-04-01T04:52:00.654801Z",
     "iopub.status.idle": "2022-04-01T04:52:00.674661Z",
     "shell.execute_reply": "2022-04-01T04:52:00.674261Z",
     "shell.execute_reply.started": "2022-04-01T04:52:00.655336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9760bbec-4c93-4214-ab33-b0d060e1c28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:52:00.675904Z",
     "iopub.status.busy": "2022-04-01T04:52:00.675376Z",
     "iopub.status.idle": "2022-04-01T04:52:00.680008Z",
     "shell.execute_reply": "2022-04-01T04:52:00.679613Z",
     "shell.execute_reply.started": "2022-04-01T04:52:00.675881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce9879-3069-4bc5-a295-dcf3ae5ecb52",
   "metadata": {},
   "source": [
    "## SMOTE - Minority Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b845ea5-5f3f-45bd-a3fe-b303705a75c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:52:00.681063Z",
     "iopub.status.busy": "2022-04-01T04:52:00.680671Z",
     "iopub.status.idle": "2022-04-01T04:52:38.249230Z",
     "shell.execute_reply": "2022-04-01T04:52:38.248769Z",
     "shell.execute_reply.started": "2022-04-01T04:52:00.681041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "over = SMOTE(sampling_strategy=0.7, random_state=11, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=1, random_state=11)\n",
    "\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X, y = pipeline.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution\n",
    "pd.concat([X, y], axis=1).pivot_table(index='target', aggfunc='size').plot(kind='bar', title = 'Class distribution').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bae509f3-ab4a-4e77-b7d4-ae1a3bb45748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:52:38.250417Z",
     "iopub.status.busy": "2022-04-01T04:52:38.250243Z",
     "iopub.status.idle": "2022-04-01T04:52:38.861483Z",
     "shell.execute_reply": "2022-04-01T04:52:38.860541Z",
     "shell.execute_reply.started": "2022-04-01T04:52:38.250397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test set with a ration of 0.7:0.3 and constant random\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0f1c5-72c1-4660-a2da-48e553951f99",
   "metadata": {},
   "source": [
    "## Model Creation, Compiling & Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e6ef0-99ce-42a8-90d1-6726d659ccc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T04:52:38.862939Z",
     "iopub.status.busy": "2022-04-01T04:52:38.862753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.7958 - auc: 0.5163\n",
      "Epoch 2/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6989 - auc: 0.6103\n",
      "Epoch 3/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6768 - auc: 0.6451\n",
      "Epoch 4/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6713 - auc: 0.6523\n",
      "Epoch 5/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6677 - auc: 0.6591\n",
      "Epoch 6/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6678 - auc: 0.6586\n",
      "Epoch 7/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6654 - auc: 0.6610\n",
      "Epoch 8/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6665 - auc: 0.6605\n",
      "Epoch 9/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6664 - auc: 0.6605\n",
      "Epoch 10/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6665 - auc: 0.6609\n",
      "Epoch 11/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6654 - auc: 0.6618\n",
      "Epoch 12/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6661 - auc: 0.6601\n",
      "Epoch 13/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6644 - auc: 0.6634\n",
      "Epoch 14/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6661 - auc: 0.6619\n",
      "Epoch 15/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6656 - auc: 0.6607\n",
      "Epoch 16/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6655 - auc: 0.6614\n",
      "Epoch 17/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6655 - auc: 0.6623\n",
      "Epoch 18/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6647 - auc: 0.6630\n",
      "Epoch 19/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6659 - auc: 0.6612\n",
      "Epoch 20/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6660 - auc: 0.6599\n",
      "Epoch 21/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6653 - auc: 0.6605\n",
      "Epoch 22/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6648 - auc: 0.6619\n",
      "Epoch 23/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6660 - auc: 0.6609\n",
      "Epoch 24/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6663 - auc: 0.6591\n",
      "Epoch 25/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6651 - auc: 0.6606\n",
      "Epoch 26/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6652 - auc: 0.6623\n",
      "Epoch 27/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6651 - auc: 0.6610\n",
      "Epoch 28/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6645 - auc: 0.6628\n",
      "Epoch 29/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6658 - auc: 0.6612\n",
      "Epoch 30/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6654 - auc: 0.6626\n",
      "Epoch 31/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6654 - auc: 0.6602\n",
      "Epoch 32/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6657 - auc: 0.6601\n",
      "Epoch 33/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6657 - auc: 0.6620\n",
      "Epoch 34/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6650 - auc: 0.6628\n",
      "Epoch 35/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6651 - auc: 0.6602\n",
      "Epoch 36/100\n",
      "5510/5510 [==============================] - 26s 5ms/step - loss: 0.6645 - auc: 0.6633\n",
      "Epoch 37/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6658 - auc: 0.6605\n",
      "Epoch 38/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6660 - auc: 0.6613\n",
      "Epoch 39/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6655 - auc: 0.6615\n",
      "Epoch 40/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6662 - auc: 0.6600\n",
      "Epoch 41/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6660 - auc: 0.6598\n",
      "Epoch 42/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6659 - auc: 0.6616\n",
      "Epoch 43/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6652 - auc: 0.6630\n",
      "Epoch 44/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6650 - auc: 0.6618\n",
      "Epoch 45/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6668 - auc: 0.6584\n",
      "Epoch 46/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6643 - auc: 0.6633\n",
      "Epoch 47/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6658 - auc: 0.6616\n",
      "Epoch 48/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6657 - auc: 0.6616\n",
      "Epoch 49/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6662 - auc: 0.6592\n",
      "Epoch 50/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6661 - auc: 0.6598\n",
      "Epoch 51/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6659 - auc: 0.6593\n",
      "Epoch 52/100\n",
      "5510/5510 [==============================] - 26s 5ms/step - loss: 0.6666 - auc: 0.6585\n",
      "Epoch 53/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6664 - auc: 0.6596\n",
      "Epoch 54/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6649 - auc: 0.6626\n",
      "Epoch 55/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6654 - auc: 0.6614\n",
      "Epoch 56/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6658 - auc: 0.6615\n",
      "Epoch 57/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6660 - auc: 0.6615\n",
      "Epoch 58/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6653 - auc: 0.6628\n",
      "Epoch 59/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6667 - auc: 0.6601\n",
      "Epoch 60/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6650 - auc: 0.6636\n",
      "Epoch 61/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6652 - auc: 0.6624\n",
      "Epoch 62/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6654 - auc: 0.6607\n",
      "Epoch 63/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6661 - auc: 0.6615\n",
      "Epoch 64/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6658 - auc: 0.6626\n",
      "Epoch 65/100\n",
      "5510/5510 [==============================] - 26s 5ms/step - loss: 0.6650 - auc: 0.6615\n",
      "Epoch 66/100\n",
      "5510/5510 [==============================] - 26s 5ms/step - loss: 0.6657 - auc: 0.6603\n",
      "Epoch 67/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6653 - auc: 0.6610\n",
      "Epoch 68/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6658 - auc: 0.6613\n",
      "Epoch 69/100\n",
      "5510/5510 [==============================] - 26s 5ms/step - loss: 0.6653 - auc: 0.6629\n",
      "Epoch 70/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6665 - auc: 0.6595\n",
      "Epoch 71/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6653 - auc: 0.6623\n",
      "Epoch 72/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6660 - auc: 0.6606\n",
      "Epoch 73/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6650 - auc: 0.6618\n",
      "Epoch 74/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6662 - auc: 0.6588\n",
      "Epoch 75/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6654 - auc: 0.6628\n",
      "Epoch 76/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6652 - auc: 0.6614\n",
      "Epoch 77/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6655 - auc: 0.6614\n",
      "Epoch 78/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6650 - auc: 0.6625\n",
      "Epoch 79/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6658 - auc: 0.6618\n",
      "Epoch 80/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6659 - auc: 0.6613\n",
      "Epoch 81/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6656 - auc: 0.6608\n",
      "Epoch 82/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6647 - auc: 0.6632\n",
      "Epoch 83/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6660 - auc: 0.6615\n",
      "Epoch 84/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6668 - auc: 0.6595\n",
      "Epoch 85/100\n",
      "5510/5510 [==============================] - 24s 4ms/step - loss: 0.6644 - auc: 0.6608\n",
      "Epoch 86/100\n",
      "5510/5510 [==============================] - 25s 4ms/step - loss: 0.6653 - auc: 0.6617\n",
      "Epoch 87/100\n",
      "5510/5510 [==============================] - 25s 5ms/step - loss: 0.6657 - auc: 0.6608\n",
      "Epoch 88/100\n",
      "3082/5510 [===============>..............] - ETA: 11s - loss: 0.6652 - auc: 0.6635"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(200,1)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['AUC'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1985c7-7607-4c44-b886-5c86956e6ad9",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54548d5-2254-42e8-8e85-477d2464630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_score = model.predict(X_test)[:,0]\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "prec, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 8))\n",
    "cm_display.plot(ax=ax1)\n",
    "roc_display.plot(ax=ax2)\n",
    "pr_display.plot(ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32d2fe-6276-43ba-ac1a-6b051616e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc666f87-8dc7-43d4-9744-ee012c123f8d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
